{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:15.363920Z",
     "start_time": "2018-02-02T15:15:14.337886Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing and Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open('log.txt').readlines()\n",
    "first = lines[0]\n",
    "first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String manipulation based on character positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str = first.split('[', 1)[1].split(' ', 1)[0]\n",
    "day, month, rest = time_str.split('/')\n",
    "year, hour, minute, second = rest.split(':')\n",
    "year, month, day, hour, minute, second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_strs = (pd.Series(lines).str.split('[', 1, expand=True)[1]\n",
    "             .str.split(' ', 1, expand=True)[0])\n",
    "day_month_rest = time_strs.str.split('/', expand=True)\n",
    "pd.concat([day_month_rest.loc[:, 0:1], \n",
    "           day_month_rest[2].str.split(':', expand=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String manipulation based on regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = r'(\\d+)/(\\w+)/(\\d+):(\\d+):(\\d+):(\\d+)'\n",
    "day, month, year, hour, minute, second = re.search(pattern, first).groups()\n",
    "year, month, day, hour, minute, second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(lines).str.extract(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date parsing using the `datetime` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "datetime.strptime(time_str, '%d/%b/%Y:%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(lines).str.extract(r'\\[(.*) -0800\\]')[0].apply(\n",
    "    lambda s: datetime.strptime(s, '%d/%b/%Y:%H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing Case Study\n",
    "\n",
    "In this example, we will apply string processing to the process of data cleaning and exploratory data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Data\n",
    "\n",
    "The city of Berkeley maintains an [Open Data Portal](https://data.cityofberkeley.info/) for citizens to access data about the city.  We will be examining [Call Data](https://data.cityofberkeley.info/Public-Safety/Berkeley-PD-Calls-for-Service/k2nh-s5h5).\n",
    "\n",
    "<img src=\"calls_desc.png\" width=800px />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.115040Z",
     "start_time": "2018-02-02T15:15:19.070620Z"
    }
   },
   "outputs": [],
   "source": [
    "import ds100_utils\n",
    "\n",
    "calls_url = 'https://data.cityofberkeley.info/api/views/k2nh-s5h5/rows.csv?accessType=DOWNLOAD'\n",
    "calls_file = ds100_utils.fetch_and_cache(calls_url, 'calls.csv')\n",
    "calls = pd.read_csv(calls_file, warn_bad_lines=True)\n",
    "calls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many records did we get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.122345Z",
     "start_time": "2018-02-02T15:15:19.118071Z"
    }
   },
   "outputs": [],
   "source": [
    "len(calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does an example `Block_Location` value look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calls['Block_Location'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Preliminary observations on the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "1. `EVENTDT` -- Contains the incorrect time\n",
    "1. `EVENTTM` -- Contains the time in 24 hour format (What timezone?)\n",
    "1. `CVDOW` -- Encodes the day of the week (see data documentation).\n",
    "1. `InDbDate` -- Appears to be correctly formatted and appears pretty consistent in time.\n",
    "1. **`Block_Location` -- a multi-line string that contains coordinates.**\n",
    "1. `BLKADDR` -- Appears to be the address in `Block Location`.\n",
    "1. `City` and `State` seem redundant given this is supposed to be the city of Berkeley dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting locations\n",
    "\n",
    "The block location contains geographic coordinates. Let's extract them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.230720Z",
     "start_time": "2018-02-02T15:15:19.225971Z"
    }
   },
   "outputs": [],
   "source": [
    "calls['Block_Location'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.268222Z",
     "start_time": "2018-02-02T15:15:19.233193Z"
    }
   },
   "outputs": [],
   "source": [
    "calls_lat_lon = (\n",
    "    calls['Block_Location']\n",
    "    .str.extract(\"\\((\\d+\\.\\d+)\\, (-\\d+\\.\\d+)\\)\")\n",
    ")\n",
    "calls_lat_lon.columns = ['Lat', 'Lon']\n",
    "calls_lat_lon.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many records have missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.280471Z",
     "start_time": "2018-02-02T15:15:19.271307Z"
    }
   },
   "outputs": [],
   "source": [
    "calls_lat_lon.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls[calls_lat_lon.isnull().any(axis=1)]['Block_Location'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join in the extracted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.328544Z",
     "start_time": "2018-02-02T15:15:19.287625Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'Lat' not in calls.columns:\n",
    "    calls = calls.merge(calls_lat_lon, left_index=True, right_index=True)\n",
    "calls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Location information\n",
    "\n",
    "Let's examine the geographic data (latitude and longitude).  Recall that we had some missing values.  Let's look at the behavior of these missing values according to crime type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:34.130428Z",
     "start_time": "2018-02-02T15:15:32.851717Z"
    }
   },
   "outputs": [],
   "source": [
    "missing_lat_lon = calls[calls[['Lat', 'Lon']].isnull().any(axis=1)]\n",
    "missing_lat_lon['CVLEGEND'].value_counts().plot(kind='barh');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls['CVLEGEND'].value_counts().plot(kind='barh');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a clear bias towards drug violations that is not present in the original data.  Therefore we should be careful when dropping missing values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might further normalize the analysis by the frequency to find which type of crime has the highest proportion of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:35.358758Z",
     "start_time": "2018-02-02T15:15:34.132788Z"
    }
   },
   "outputs": [],
   "source": [
    "(missing_lat_lon['CVLEGEND'].value_counts() \n",
    " / calls['CVLEGEND'].value_counts()\n",
    ").sort_values(ascending=False).plot(kind=\"barh\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make a crime map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import folium.plugins\n",
    "\n",
    "SF_COORDINATES = (37.87, -122.28)\n",
    "sf_map = folium.Map(location=SF_COORDINATES, zoom_start=13)\n",
    "locs = calls[['Lat', 'Lon']].astype('float').dropna().values\n",
    "heatmap = folium.plugins.HeatMap(locs.tolist(), radius=10)\n",
    "sf_map.add_child(heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. Is campus really the safest place to be?\n",
    "1. Why are all the calls located on the street and at often at intersections?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:54.826669Z",
     "start_time": "2018-02-02T15:15:37.180513Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "locations = calls[calls['CVLEGEND'] == 'ASSAULT'][['Lat', 'Lon']]\n",
    "\n",
    "cluster = MarkerCluster([])\n",
    "for _, r in locations.dropna().iterrows():\n",
    "    cluster.add_child(\n",
    "        folium.Marker([float(r[\"Lat\"]), float(r[\"Lon\"])]))\n",
    "    \n",
    "sf_map = folium.Map(location=SF_COORDINATES, zoom_start=13)\n",
    "sf_map.add_child(cluster)\n",
    "sf_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
